{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f01008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    #for filename in filenames:\n",
    "        #print(os.path.join(dirname, filename))\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten,Dense,Dropout,BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "from tensorflow.keras.applications import VGG16, InceptionResNetV2\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop,SGD,Adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b61f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"train\" #passing the path with training images\n",
    "test_dir = \"test\"   #passing the path with testing images\n",
    "validation_dir = \"validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe89d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 48 #original size of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb4274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data Augmentation\n",
    "--------------------------\n",
    "rotation_range = rotates the image with the amount of degrees we provide\n",
    "width_shift_range = shifts the image randomly to the right or left along the width of the image\n",
    "height_shift range = shifts image randomly to up or below along the height of the image\n",
    "horizontal_flip = flips the image horizontally\n",
    "rescale = to scale down the pizel values in our image between 0 and 1\n",
    "zoom_range = applies random zoom to our object\n",
    "validation_split = reserves some images to be used for validation purpose\n",
    "\"\"\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(#rotation_range = 180,\n",
    "                                         width_shift_range = 0.1,\n",
    "                                         height_shift_range = 0.1,\n",
    "                                         horizontal_flip = True,\n",
    "                                         rescale = 1./255,\n",
    "                                         #zoom_range = 0.2,\n",
    "                                         validation_split = 0.2\n",
    "                                        )\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                         validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fad75cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Applying data augmentation to the images as we read \n",
    "them from their respectivve directories\n",
    "\"\"\"\n",
    "train_generator = train_datagen.flow_from_directory(directory = train_dir,\n",
    "                                                    target_size = (img_size,img_size),\n",
    "                                                    batch_size = 64,\n",
    "                                                    color_mode = \"grayscale\",\n",
    "                                                    class_mode = \"categorical\"\n",
    "                                                   )\n",
    "validation_generator = validation_datagen.flow_from_directory( directory = validation_dir,\n",
    "                                                              target_size = (img_size,img_size),\n",
    "                                                              batch_size = 64,\n",
    "                                                              color_mode = \"grayscale\",\n",
    "                                                              class_mode = \"categorical\"\n",
    "                                                             )\n",
    "test_generator = validation_datagen.flow_from_directory(  directory=test_dir,\n",
    "                                                    target_size=(img_size, img_size),\n",
    "                                                    batch_size=64,\n",
    "                                                    color_mode=\"grayscale\",\n",
    "                                                    class_mode=\"categorical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381ebb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class_counts = train_generator.classes\n",
    "unique_classes, class_counts = np.unique(train_class_counts, return_counts=True)\n",
    "\n",
    "# Sınıf adları\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "\n",
    "# Bar grafiği çizin\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(class_names, class_counts)\n",
    "plt.xlabel('Sınıf Adları')\n",
    "plt.ylabel('Veri Sayısı')\n",
    "plt.title('Train Veri Setindeki Sınıf Dağılımı')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46903f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= tf.keras.models.Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding='same', activation='relu', input_shape=(48, 48,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3), padding='same', activation='relu' ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "model.add(Conv2D(128, (3,3), padding='same', activation='relu' ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3,3), padding='same', activation='relu' ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3,3), padding='same', activation='relu' ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(256, (3,3), padding='same', activation='relu' ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3,3), padding='same', activation='relu' ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3,3), padding='same', activation='relu' ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3,3), padding='same', activation='relu' ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(256, (3,3), padding='same', activation='relu' ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3,3), padding='same', activation='relu' ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3,3), padding='same', activation='relu' ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3,3), padding='same', activation='relu' ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(512, (3,3), padding='same', activation='relu' ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512, (3,3), padding='same', activation='relu' ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512, (3,3), padding='same', activation='relu' ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512, (3,3), padding='same', activation='relu' ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33fb4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = Adam(learning_rate=0.0001), \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c475da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7010d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb67c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abc1c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeli eğitme\n",
    "history = model.fit(x=train_generator,\n",
    "                         steps_per_epoch=len(train_generator),\n",
    "                         epochs=epochs,\n",
    "                         batch_size=batch_size,\n",
    "                         validation_data=validation_generator,\n",
    "                         validation_steps=len(validation_generator),\n",
    "                         callbacks=[early_stopping]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f480a411",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , ax = plt.subplots(1,2)\n",
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "fig.set_size_inches(12,4)\n",
    "\n",
    "ax[0].plot(history.history['accuracy'])\n",
    "ax[0].plot(history.history['val_accuracy'])\n",
    "ax[0].set_title('Training Accuracy vs Validation Accuracy')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "ax[1].plot(history.history['loss'])\n",
    "ax[1].plot(history.history['val_loss'])\n",
    "ax[1].set_title('Training Loss vs Validation Loss')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.show()     #hpcye yollarken yorum satırı\n",
    "\n",
    "#fig.savefig('plot.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c61e989",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_optimal.h5')\n",
    "model.save_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c54adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model, Sequential\n",
    "\n",
    "def load_model_with_weights(model_filename, weights_filename):\n",
    "    # Modeli yükle\n",
    "    loaded_model = load_model(model_filename)\n",
    "    \n",
    "    # Yüklü modelin katmanlarını al\n",
    "    layers = loaded_model.layers\n",
    "    \n",
    "    # Ağırlıkları içeren yeni bir model oluştur ve ağırlıkları yükle\n",
    "    model = Sequential(layers)\n",
    "    model.load_weights(weights_filename)\n",
    "    \n",
    "    # Modeli derle\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32fc3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeli ve ağırlıkları yükle\n",
    "loaded_model = load_model_with_weights('model_optimal.h5', 'model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe822e74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Yüklenmiş modeli kullanabilirsiniz\n",
    "predictions = loaded_model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6872335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "true_labels = test_generator.classes\n",
    "predicted_labels = np.argmax(predictions, axis=1)  # En yüksek olasılığa sahip sınıfı seç\n",
    "accuracy = accuracy_score(true_labels, predicted_labels, normalize=True)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e2ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels, normalize='true')\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aaa628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Karmaşıklık matrisini görselleştirme\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='.2g', cmap='Blues', \n",
    "            xticklabels=validation_generator.class_indices.keys(), \n",
    "            yticklabels=validation_generator.class_indices.keys())\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93df7e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
    "for i, accuracy in enumerate(class_accuracies):\n",
    "    print(f\"Class {i}: Accuracy = {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4101328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class_report = classification_report(true_labels, predicted_labels, target_names=validation_generator.class_indices.keys())\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fde73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b63271",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d54c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    height, width, channel = frame.shape\n",
    "    \n",
    "    sub_img = frame[0:int(height/6), 0:int(width)]\n",
    "    black_rect = np.ones(sub_img.shape, dtype=np.uint8) * 0\n",
    "    res = cv2.addWeighted(sub_img, 0.77, black_rect, 0.23, 0)\n",
    "    FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    FONT_SCALE = 0.8\n",
    "    FONT_THICKNESS = 2\n",
    "    lable_color = (10, 10, 255)\n",
    "    lable = \"Cenk's Emotion Detection\"\n",
    "    lable_dimension = cv2.getTextSize(lable, FONT, FONT_SCALE, FONT_THICKNESS)[0]\n",
    "    textX = int((res.shape[1] - lable_dimension[0]) / 2)\n",
    "    textY = int((res.shape[0] + lable_dimension[1]) / 2)\n",
    "    cv2.putText(res, lable, (textX, textY), FONT, FONT_SCALE, (0, 0, 0), FONT_THICKNESS)\n",
    "    gray_image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_haar_cascade.detectMultiScale(gray_image)\n",
    "    \n",
    "    if len(faces) > 0:\n",
    "        x, y, w, h = faces[0]\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        roi_gray = gray_image[y:y+h, x:x+w]\n",
    "        roi_gray = cv2.resize(roi_gray, (48, 48))\n",
    "        image_pixels = img_to_array(roi_gray)\n",
    "        image_pixels = np.expand_dims(image_pixels, axis=0)\n",
    "        image_pixels /= 255\n",
    "        predictions = loaded_model.predict(image_pixels,verbose=0)\n",
    "        max_index = np.argmax(predictions[0])\n",
    "        emotion_detection = ('angry', 'fear', 'happy', 'neutral', 'sad', 'surprise')\n",
    "        emotion_prediction = emotion_detection[max_index]\n",
    "        cv2.putText(res, \"Sentiment: {}\".format(emotion_prediction), (0, textY+22+5), FONT, 0.7, lable_color, 2)\n",
    "        lable_violation = 'Confidence: {}'.format(str(np.round(np.max(predictions[0])*100, 1)) + \"%\")\n",
    "        violation_text_dimension = cv2.getTextSize(lable_violation, FONT, FONT_SCALE, FONT_THICKNESS)[0]\n",
    "        violation_x_axis = int(res.shape[1] - violation_text_dimension[0])\n",
    "        cv2.putText(res, lable_violation, (violation_x_axis, textY+22+5), FONT, 0.7, lable_color, 2)\n",
    "    \n",
    "    frame[0:int(height/6), 0:int(width)] = res\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa29cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuma",
   "language": "python",
   "name": "cuma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
